{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "迁移学习教程\n",
    "==========================\n",
    "在本教程中，你将学到如何使用迁移学习训练网络。\n",
    "\n",
    "了解更多关于迁移学习的内容[cs231n notes](http://cs231n.github.io/transfer-learning/)\n",
    "\n",
    "实际中，很少有人从头开始训练卷积神经网络。因为很难有足够规模的数据集。相反地，在很大的数据集上预训练一个卷积神经网络是常见的。例如 ImageNet，包含 1.2 百万个图像与 1000 个类别。然后使用卷积神经网络作为感兴趣的任务的初始化或固定特征提取器。\n",
    "\n",
    "两个主要的迁移学习场景：\n",
    "\n",
    "-  **调整卷积神经网络**: 与随机初始化不同，我们使用预训练网络初始化一个网络，如同在 imagenet 1000 数据集训练过，其余训练与往常相同。\n",
    "-  **卷积神经网络作为固定特征提取器**: 我们将冻结除最终完全连接层之外的所有网络的权重。最后一个完全连接的层被替换为具有随机权重的新层，并且仅训练该层。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# License: BSD\n",
    "# Author: Sasank Chilamkurthy\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "plt.ion()   # 交互模式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "装载数据\n",
    "---------\n",
    "\n",
    "使用 torchvision 和 torch.utils.data 包装载数据。\n",
    "\n",
    "本文要解决的问题是训练一个模型来对**蚂蚁**和**蜜蜂**分类，各自有 120 张训练图。每一类有 75 张验证图。通常地，如果从头学习，这是一个很小的数据集，不易泛化。而我们使用迁移学习，应该能合理地泛化。\n",
    "\n",
    "这是 imagenet 数据集的一个很小的子集。\n",
    "\n",
    "注意：从[此处](https://download.pytorch.org/tutorial/hymenoptera_data.zip)下载数据并解压到当前目录。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练集：数据增强与归一化\n",
    "# 验证集：仅归一化\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([ # 将多个图像变换组合到一起\n",
    "        transforms.RandomResizedCrop(224), # 将给定的 PIL 图像裁剪为随机大小和纵横比例\n",
    "        transforms.RandomHorizontalFlip(), # 以概率 0.5 随机水平翻转图像\n",
    "        transforms.ToTensor(), # 转换一个 PIL Image 或 numpy.ndarray 为 tensor\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) \n",
    "        # 用均值和标准偏差对张量图像进行归一化，这里是3个通道\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256), # 将输入 PIL 图像的大小调整为给定大小\n",
    "        transforms.CenterCrop(224), # 将给定的PIL图像裁剪为中心\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = 'hymenoptera_data' # 数据目录\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "让我们可视化一些训练图片来理解数据增强。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))  # 交换轴\n",
    "    mean = np.array([0.485, 0.456, 0.406])  # 均值\n",
    "    std = np.array([0.229, 0.224, 0.225])  # 标准差\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # 稍微暂停以便更新图表\n",
    "\n",
    "\n",
    "# 获得一批训练数据\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "\n",
    "# 在一批数据中分出小格\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练模型\n",
    "------------------\n",
    "\n",
    "现在写一些通用函数来训练一个模型。此处，我们会阐述：\n",
    "\n",
    "-  调整学习率\n",
    "-  保存最佳模型\n",
    "\n",
    "在下文，参数**scheduler**是一个学习率调整的对象，来自**torch.optim.lr_scheduler**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # 每次迭代有一个训练和验证阶段\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # 模型设置为训练模式\n",
    "            else:\n",
    "                model.eval()  # 模型设置为评估模式\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # 数据上迭代\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # 清零参数梯度\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # 前向\n",
    "                # 只在训练时追踪历史\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # 仅在训练阶段，反向与优化\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # 统计\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]  # 本次迭代的损失\n",
    "            epoch_acc = running_corrects.double(\n",
    "            ) / dataset_sizes[phase]  # 本次迭代的准确度\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss,\n",
    "                                                       epoch_acc))\n",
    "\n",
    "            # 深拷贝模型\n",
    "            if phase == 'val' and epoch_acc > best_acc:  # 本次迭代的准确率是目前最优的，存储最佳模型\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # 装载最佳模型\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 可视化模型预测\n",
    "\n",
    "展示对一些图像的预测的通用函数\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(model, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    with torch.no_grad():  # 不跟踪梯度\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
    "            inputs = inputs.to(device)  # 输入\n",
    "            labels = labels.to(device)  # 标签\n",
    "\n",
    "            outputs = model(inputs)  # 预测值\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images // 2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
    "                imshow(inputs.cpu().data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "调整卷积神经网络\n",
    "----------------------\n",
    "\n",
    "装载一个预训练模型并重置最后的全连接层。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = models.resnet18(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 注意所有参数都被优化\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# 每7次迭代衰减学习率0.1倍\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练与评估\n",
    "\n",
    "会花费 CPU 15-25 分钟时间，使用 GPU 在 1 分钟以内。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_model(model_ft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "卷积神经网络作为固定特征提取器\n",
    "----------------------------------\n",
    "\n",
    "冻结整个网络，除了最后一层。我们需要将 ``requires_grad == False`` 以冻结参数，梯度不会被计算在``backward()``中。\n",
    "\n",
    "了解更多[点击此处](http://pytorch.org/docs/notes/autograd.html#excluding-subgraphs-from-backward)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv = torchvision.models.resnet18(pretrained=True)\n",
    "for param in model_conv.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 默认情况下，新构建的模块的参数具有 requires_grad = True\n",
    "num_ftrs = model_conv.fc.in_features\n",
    "model_conv.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_conv = model_conv.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 注意只有最后一层的参数才会被优化，这与之前不同\n",
    "optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# 每7次迭代，学习率衰退0.1倍\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练和评估\n",
    "\n",
    "与之前场景相比，在 CPU 上这将花费约一半时间，因为网络大部分不需要计算梯度。\n",
    "\n",
    "然而，前向传播是必须计算的。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv = train_model(model_conv, criterion, optimizer_conv,\n",
    "                         exp_lr_scheduler, num_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_model(model_conv)\n",
    "\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
